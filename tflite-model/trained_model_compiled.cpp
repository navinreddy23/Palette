/* Generated by Edge Impulse
 *
 * Permission is hereby granted, free of charge, to any person obtaining a copy
 * of this software and associated documentation files (the "Software"), to deal
 * in the Software without restriction, including without limitation the rights
 * to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
 * copies of the Software, and to permit persons to whom the Software is
 * furnished to do so, subject to the following conditions:
 *
 * The above copyright notice and this permission notice shall be included in
 * all copies or substantial portions of the Software.
 *
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
 * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
 * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
 * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
 * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
 * OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
 * SOFTWARE.
 */
// Generated on: 05.06.2022 10:34:44

#include <stdio.h>
#include <stdlib.h>
#include <vector>
#include "edge-impulse-sdk/tensorflow/lite/c/builtin_op_data.h"
#include "edge-impulse-sdk/tensorflow/lite/c/common.h"
#include "edge-impulse-sdk/tensorflow/lite/micro/micro_mutable_op_resolver.h"
#include "edge-impulse-sdk/porting/ei_classifier_porting.h"

#if EI_CLASSIFIER_PRINT_STATE
#if defined(__cplusplus) && EI_C_LINKAGE == 1
extern "C" {
    extern void ei_printf(const char *format, ...);
}
#else
extern void ei_printf(const char *format, ...);
#endif
#endif

#if defined __GNUC__
#define ALIGN(X) __attribute__((aligned(X)))
#elif defined _MSC_VER
#define ALIGN(X) __declspec(align(X))
#elif defined __TASKING__
#define ALIGN(X) __align(X)
#endif

using namespace tflite;
using namespace tflite::ops;
using namespace tflite::ops::micro;

namespace {

constexpr int kTensorArenaSize = 2192;

#if defined(EI_CLASSIFIER_ALLOCATION_STATIC)
uint8_t tensor_arena[kTensorArenaSize] ALIGN(16);
#elif defined(EI_CLASSIFIER_ALLOCATION_STATIC_HIMAX)
#pragma Bss(".tensor_arena")
uint8_t tensor_arena[kTensorArenaSize] ALIGN(16);
#pragma Bss()
#elif defined(EI_CLASSIFIER_ALLOCATION_STATIC_HIMAX_GNU)
uint8_t tensor_arena[kTensorArenaSize] ALIGN(16) __attribute__((section(".tensor_arena")));
#else
#define EI_CLASSIFIER_ALLOCATION_HEAP 1
uint8_t* tensor_arena = NULL;
#endif

static uint8_t* tensor_boundary;
static uint8_t* current_location;

template <int SZ, class T> struct TfArray {
  int sz; T elem[SZ];
};
enum used_operators_e {
  OP_RESHAPE, OP_CONV_2D, OP_MAX_POOL_2D, OP_FULLY_CONNECTED, OP_SOFTMAX,  OP_LAST
};
struct TensorInfo_t { // subset of TfLiteTensor used for initialization from constant memory
  TfLiteAllocationType allocation_type;
  TfLiteType type;
  void* data;
  TfLiteIntArray* dims;
  size_t bytes;
  TfLiteQuantization quantization;
};
struct NodeInfo_t { // subset of TfLiteNode used for initialization from constant memory
  struct TfLiteIntArray* inputs;
  struct TfLiteIntArray* outputs;
  void* builtin_data;
  used_operators_e used_op_index;
};

TfLiteContext ctx{};
TfLiteTensor tflTensors[15];
TfLiteEvalTensor tflEvalTensors[15];
TfLiteRegistration registrations[OP_LAST];
TfLiteNode tflNodes[7];

const TfArray<2, int> tensor_dimension0 = { 2, { 1,300 } };
const TfArray<1, float> quant0_scale = { 1, { 274.40582275390625, } };
const TfArray<1, int> quant0_zero = { 1, { -3 } };
const TfLiteAffineQuantization quant0 = { (TfLiteFloatArray*)&quant0_scale, (TfLiteIntArray*)&quant0_zero, 0 };
const ALIGN(16) int32_t tensor_data1[4] = { 1, 1, 5, 60, };
const TfArray<1, int> tensor_dimension1 = { 1, { 4 } };
const ALIGN(16) int32_t tensor_data2[4] = { 1, 5, 1, 16, };
const TfArray<1, int> tensor_dimension2 = { 1, { 4 } };
const ALIGN(8) int32_t tensor_data3[2] = { -1, 48, };
const TfArray<1, int> tensor_dimension3 = { 1, { 2 } };
const ALIGN(16) int8_t tensor_data4[16*1*3*60] = { 
  /* [0][0][][] */ -75,-91,56,52,67,-32,-1,-44,-50,-30,-85,-26,102,-118,-12,-63,-60,76,-104,-20,81,82,-7,67,22,76,-66,-16,-20,16,-60,51,-28,-88,43,-47,106,-58,-53,-54,19,-12,90,64,-56,-52,-11,-10,-88,-62,58,30,22,-68,-26,-96,31,-44,84,92, -46,90,28,-107,-94,-73,-17,-96,-47,-23,15,-70,2,46,15,11,-44,-47,-59,-80,-65,-25,66,-97,-72,-23,-10,-88,37,-6,-16,49,-23,-75,32,58,78,10,76,99,60,42,-18,51,-76,-6,26,54,38,-68,-30,42,-44,70,38,-2,82,24,-12,-12, 39,89,95,108,-12,-101,127,104,80,107,-37,38,101,21,1,14,32,-11,13,75,-15,-62,-53,90,41,61,-60,32,69,81,101,34,13,71,-5,93,68,76,-47,-104,92,-66,6,-40,41,-40,-28,23,46,-75,-25,-101,88,42,41,69,26,-118,8,98, 
  /* [1][0][][] */ 11,-44,36,14,-11,23,94,-17,-2,41,-79,-67,75,19,-66,-20,41,-47,-4,37,-38,9,-42,93,83,-1,-101,-39,9,-40,25,95,92,-33,-35,-62,59,-57,-96,119,-104,22,47,-19,58,-21,105,-63,-14,-61,-78,-70,-11,67,53,-92,88,30,68,79, -33,2,92,-22,0,-96,-67,-35,67,73,-109,-3,92,55,-3,99,75,13,96,-2,-49,99,59,116,44,61,-17,101,-3,-35,-20,-115,48,50,-118,-74,-84,29,59,53,77,91,-49,-43,20,-49,75,71,-19,33,-24,-54,113,-91,42,-100,-69,-24,-53,4, 12,66,99,-57,58,-18,39,-8,49,63,-50,7,-62,-100,-56,-41,-14,106,-79,85,76,91,21,-76,-66,-107,43,-106,-69,-109,50,-24,37,-48,77,36,-52,22,56,-48,60,-9,-58,67,78,-66,106,69,-100,-118,71,-41,1,90,12,28,127,-70,-103,-71, 
  /* [2][0][][] */ 8,-89,-98,-83,-42,5,67,-54,26,-17,-68,-21,-25,-14,-78,-69,63,-21,2,2,-72,-38,-51,-26,-18,45,52,37,52,-71,-26,-79,-4,-73,9,-16,36,-15,83,-32,-89,76,83,62,-49,19,36,6,-41,-59,71,-36,-77,72,-35,-46,85,-5,20,76, 113,39,2,95,6,19,-55,39,52,55,54,13,19,-101,10,39,12,55,60,-44,39,72,14,72,-24,35,-73,-87,-28,42,-34,-23,0,26,-39,-74,-53,-35,47,17,38,-80,-87,-78,1,74,-76,48,52,47,-71,-48,-37,55,-7,-112,19,-79,35,4, 78,2,-13,63,95,-89,-46,-58,9,11,66,-71,-52,84,-79,-27,42,66,14,31,25,72,26,-86,80,54,84,7,63,-28,124,16,-27,82,-14,-79,127,-88,-31,-23,-85,-69,96,-43,-54,16,-52,18,72,71,-23,-41,15,45,34,-8,55,20,-42,-70, 
  /* [3][0][][] */ -99,-31,114,8,-41,41,27,90,42,-86,-1,107,91,-27,-41,26,-24,-19,-56,-11,-11,31,56,89,-19,-105,-16,-45,-17,-19,-4,76,-17,-28,25,74,-86,14,-84,74,5,94,71,79,38,8,88,48,93,37,11,-99,-56,-127,-63,-78,-54,49,-98,60, 71,-49,65,-37,45,-67,-20,32,94,4,71,65,-31,-103,-67,-102,42,-75,78,71,-65,-59,64,62,-65,-113,9,-30,-61,79,0,-1,-62,-35,58,-95,54,-52,-67,83,65,0,99,40,-15,56,-91,-96,76,-91,83,-94,93,-3,-87,-38,47,-38,-103,-62, -73,42,-43,-24,48,-17,-14,-85,74,29,9,77,100,-55,73,37,-2,-6,8,22,-34,99,70,48,57,-3,-42,97,-86,35,42,-13,106,53,-64,-18,59,-5,5,-53,-102,109,-57,109,-94,71,-26,1,34,-58,83,-49,-15,60,41,39,-80,-33,87,-30, 
  /* [4][0][][] */ 3,-71,63,18,-94,27,7,-1,3,-20,25,10,27,-14,73,-7,96,-96,88,-72,-76,-35,55,-101,1,11,-121,-98,99,-57,-6,-66,12,-80,30,93,-28,90,40,35,-46,90,76,-96,4,57,73,-35,-63,20,18,98,104,17,86,-103,5,28,63,50, 76,9,35,-35,-79,23,103,27,93,-6,58,-16,9,64,39,-83,-30,-32,61,109,109,-38,-36,94,41,-13,-67,91,-99,-66,16,20,-6,-93,96,36,105,41,-44,-19,-20,51,127,105,-25,64,33,57,-48,52,-67,75,-20,88,-8,49,63,61,16,46, -62,48,84,-83,-69,-52,-57,68,-9,-98,-30,-80,20,32,-67,-27,33,1,-53,-22,-35,-10,-89,-6,-53,63,31,35,68,56,-42,52,-80,-10,-90,94,-77,-2,72,-36,-19,-66,-50,-18,-72,20,-67,72,107,-73,-52,113,-31,60,-30,14,-9,64,88,-53, 
  /* [5][0][][] */ 66,10,33,-26,59,-10,113,-62,82,-36,3,69,9,102,-12,116,-95,-41,2,-60,-35,-89,-16,31,-101,-63,-39,-25,51,101,-86,-72,11,76,-75,70,-3,56,-90,51,-1,-12,15,78,126,4,55,27,58,83,22,36,63,82,65,-42,-82,118,-76,-9, -14,-74,-64,-69,102,-35,-50,108,94,-112,19,118,-31,-96,53,-31,4,-27,115,-66,45,-69,-33,40,-62,24,-5,12,101,-51,-52,-71,-78,93,14,26,-98,-52,-12,-87,-88,-70,-112,51,63,102,3,-4,72,-49,-58,-119,-61,-17,28,-100,-49,82,78,-12, 55,107,-45,69,-56,4,97,120,7,-77,101,107,-17,63,-25,-46,-41,-45,118,9,116,-21,21,49,41,13,-73,-46,-91,127,-57,-10,73,-49,-112,29,-82,-68,-12,0,-72,-51,-45,-62,93,-39,-28,117,-21,115,-20,108,38,-2,42,-29,44,-85,-57,65, 
  /* [6][0][][] */ -90,-110,-18,121,-81,-44,23,48,62,8,-49,11,-32,-89,102,-98,-20,-12,6,-74,-19,-12,-14,-48,-21,28,-11,-86,-60,-101,17,99,-89,-73,69,31,-82,-7,26,-10,-66,48,-4,90,51,33,-11,-11,-96,-11,99,-16,-108,83,88,-18,23,92,72,73, 51,-106,24,-90,-42,73,-87,-73,-3,-79,-55,24,39,60,120,37,-108,-37,-28,-127,-32,-90,38,58,-28,-79,117,63,72,-23,-15,85,-82,-32,-66,26,-21,-84,-20,79,40,-51,70,-65,-84,65,95,-53,-15,-82,112,58,5,43,-17,-13,-26,-49,44,-45, 74,-25,120,12,64,62,28,-68,-103,77,-36,117,57,-62,121,-80,-96,84,-105,37,74,-39,95,-10,-37,-111,-61,97,-45,-86,86,68,-16,-29,39,-58,-37,-64,-98,-37,-20,-6,-75,-110,-46,-22,60,-28,51,54,-56,-39,5,75,-49,46,-26,-40,-12,-97, 
  /* [7][0][][] */ -50,-39,43,-14,-26,-93,20,-10,-70,93,81,88,88,-71,85,-65,45,-39,99,36,-4,-16,-99,59,73,-51,-70,62,36,17,-21,82,101,62,102,32,17,-122,-100,35,-77,-96,57,59,-83,-117,-1,-56,-2,-55,16,-29,-26,83,-97,-75,-64,7,-84,0, 22,67,-106,-23,4,-47,98,-31,22,-64,12,7,-88,-15,47,-23,-55,-70,-67,7,-99,32,80,-48,-49,57,36,-53,72,-38,-23,-79,-52,-30,9,31,55,18,-85,-4,57,-48,104,59,82,-43,39,118,-43,91,-89,-12,44,-83,83,-117,60,-72,33,-83, -113,-56,94,15,-99,-101,-67,15,16,-69,-18,22,-62,-60,7,68,-95,54,96,-28,60,-7,105,86,-15,-18,7,100,89,-81,11,-127,-22,79,86,-97,-89,78,-3,-109,-36,-69,79,-71,64,-98,42,53,-20,77,50,11,-2,65,-49,-82,79,12,-101,4, 
  /* [8][0][][] */ 25,80,-46,65,-60,80,94,-84,10,-51,47,46,96,14,-32,7,-26,57,-78,-102,45,-53,74,-87,-25,-4,-24,99,-56,-14,-49,-37,-82,-39,31,94,0,-63,29,-57,-51,67,37,27,-45,-36,61,38,-84,100,75,-109,77,-58,95,-32,12,-35,58,-42, -71,41,60,101,-40,28,-52,10,-26,82,-101,-87,-3,-7,51,-10,18,-58,-11,-30,100,5,48,-15,112,-5,-108,112,-52,-89,64,20,-28,43,71,54,42,-4,55,63,-63,62,28,53,-21,75,-16,-41,18,-17,39,112,79,-110,66,-102,-46,5,-75,89, -28,56,12,111,-99,80,-23,80,-95,-80,-83,11,33,-107,-10,-14,55,7,68,58,-82,89,-42,22,88,54,112,-61,10,-127,-52,-18,73,-42,-87,61,87,81,-32,-98,58,24,91,94,-78,-42,33,62,109,-93,83,-121,7,-48,-30,37,107,-117,-85,60, 
  /* [9][0][][] */ 11,-61,-11,-106,85,-102,53,67,5,-26,66,-98,68,6,81,-57,-40,-67,-9,18,15,33,82,-62,95,66,-114,-91,60,-47,89,48,14,-80,10,90,43,90,50,107,-18,96,-88,-87,39,-12,13,78,-77,-91,-88,29,6,-76,-18,33,55,30,52,1, -20,-3,52,-39,-83,-54,-31,105,86,70,-101,-30,-7,49,-60,-56,-19,-50,81,-6,83,0,21,-31,77,89,-92,-110,71,-82,-49,-85,45,47,-80,67,115,74,56,100,6,15,-81,-35,-26,-117,115,-102,105,-55,20,-45,107,-7,77,70,11,-126,127,-27, 26,118,-114,44,97,4,6,-45,85,-122,11,-72,-69,-7,-21,-95,29,-61,88,-69,21,-25,97,47,-58,112,-55,-92,121,-65,44,2,9,44,13,45,58,-77,-75,9,1,109,8,-20,-8,101,-68,-16,91,-31,-61,39,-47,117,-66,54,-11,7,68,-64, 
  /* [10][0][][] */ -74,116,-78,86,-38,108,45,-104,6,65,33,64,-37,-89,-10,19,-67,66,-55,-7,-64,54,109,-91,-74,-48,-2,-58,-33,50,-58,19,25,88,-24,48,-39,-58,78,-3,-123,-3,-83,67,-100,-42,61,-53,32,-26,-35,6,-28,36,-93,49,9,86,-114,-112, -39,56,127,14,-17,-98,-36,85,65,-48,-5,51,41,-89,112,-57,-48,-99,118,-6,-62,-93,-62,-83,101,-88,7,86,42,-8,-67,81,-24,103,43,-80,31,-52,77,-8,97,33,-92,-18,64,-84,-45,8,-9,92,59,7,-19,-45,103,63,97,112,37,4, 79,-59,56,-24,-54,-64,-26,93,-34,-40,-107,-86,-83,-43,-84,102,-15,-5,-33,78,-77,54,109,27,-56,-65,-107,-89,54,-104,53,-8,75,-87,39,43,33,-18,-100,-115,-45,-49,72,113,-28,-45,-23,56,-68,57,-4,-107,16,-78,-36,64,-61,16,93,40, 
  /* [11][0][][] */ 76,110,-58,89,19,18,80,-59,27,-32,64,-72,-16,-8,73,30,-58,16,65,-58,40,-65,84,36,48,70,-54,115,78,-74,49,-66,33,7,31,-57,49,18,-70,-80,-68,-49,-42,47,-7,80,25,-77,36,88,-16,-97,-20,90,-28,-72,102,66,-10,88, -19,15,105,75,61,72,79,-79,-18,45,84,77,54,28,-66,-38,54,-36,21,-29,24,19,-30,81,-95,43,-44,35,74,-33,-1,104,31,-98,71,-82,9,-44,-8,92,-85,71,-48,-18,-33,21,28,60,3,54,-21,97,-7,-46,0,34,-74,69,60,-12, -4,-87,52,112,6,-96,-2,-88,66,-34,44,23,-9,-3,3,75,-17,42,-69,41,-91,-36,22,26,-52,-64,75,26,65,-69,56,73,102,72,91,86,80,-88,-63,-7,-68,70,-63,-127,-6,64,2,-75,52,-47,-15,-15,-83,-50,-54,57,3,17,80,26, 
  /* [12][0][][] */ 68,52,-48,8,25,79,76,-81,-63,-61,-7,-93,58,-53,-71,-87,-31,-95,127,59,77,-25,41,-69,0,-93,-12,-44,-64,90,-84,114,117,48,31,94,6,24,-79,-17,-18,52,-53,-29,51,-56,26,-76,-9,61,-5,-91,-66,62,-82,-1,28,94,56,82, -14,99,69,84,87,-38,-74,74,46,10,74,37,53,5,-27,-89,76,-38,-22,106,-6,94,10,50,48,98,-91,-50,-78,-87,40,119,43,98,-116,4,74,4,84,101,-4,-26,79,91,-90,-77,-23,-15,53,-59,0,-33,-85,-83,111,-70,-12,94,-42,-50, -91,-88,125,103,72,86,91,-54,-39,-10,-41,59,-70,-72,60,57,43,59,-1,-40,35,-32,-51,18,-52,46,-93,-85,-19,106,-30,29,-77,111,109,-19,-69,127,-46,50,-60,118,-52,-89,81,-34,52,70,-28,-90,86,10,118,74,107,41,-53,17,61,-59, 
  /* [13][0][][] */ 15,27,12,-55,-80,11,-1,30,108,54,36,-20,-44,-36,70,34,2,72,-34,-17,-31,78,74,45,87,-86,-33,-24,-50,-80,-89,-63,49,48,102,88,66,54,127,21,35,-73,-22,93,-55,95,79,97,-48,25,6,-36,91,4,72,-49,-41,-84,0,86, -12,73,16,103,77,-15,84,-14,14,-62,30,-46,49,-70,-52,2,-27,76,45,79,30,89,67,-71,-58,-99,72,-89,49,66,-16,12,-22,21,68,41,49,27,-60,-84,16,-71,12,-104,-71,67,37,-22,71,-87,-41,13,19,6,-83,-73,-55,-70,70,-42, 44,-93,-77,-95,40,-64,4,-4,62,-55,-15,-17,-7,-1,39,-97,80,17,15,64,55,-90,24,-70,59,-72,-30,50,-5,45,-57,-46,8,-67,89,-79,9,25,61,-43,45,-84,-27,-97,22,78,-93,73,67,34,-59,61,3,21,-28,64,87,-59,44,6, 
  /* [14][0][][] */ -71,-93,-8,60,66,50,-36,22,-13,-58,-11,69,-84,-37,-59,-77,71,87,-84,58,-47,67,19,-106,-15,6,13,98,20,93,61,18,-46,-54,-22,-55,-81,37,79,35,87,-16,-30,32,65,21,29,-6,-62,65,-3,2,-72,-24,-43,-32,64,78,-7,32, 73,-83,38,3,-78,48,-2,-83,56,-67,-34,74,-1,89,37,-98,21,4,24,-75,-90,-54,32,-2,78,-70,-41,-102,41,-66,65,-47,-11,50,-70,70,-107,82,7,-68,44,80,-52,22,-58,-52,53,-58,38,11,-45,59,-40,15,85,60,30,-101,38,78, -88,-13,127,-29,36,-73,-25,60,8,82,-54,17,48,87,-10,72,69,82,34,97,48,26,-45,6,45,51,86,15,-70,75,-40,-16,30,82,-49,-9,47,96,-60,-44,-54,-104,-45,-10,-71,-20,-79,65,-9,14,-39,15,21,68,102,62,-39,-81,-32,93, 
  /* [15][0][][] */ -57,60,-81,63,35,-27,122,19,10,-75,-36,102,89,-96,77,-26,-97,-61,-38,33,-13,80,-16,65,-4,24,-45,-93,-28,-98,-40,-75,77,-31,89,6,76,-97,85,-81,-104,-48,21,82,21,-39,53,37,17,-19,98,-48,77,51,56,-37,-10,30,-68,71, -23,20,93,-82,96,25,126,41,-70,-18,9,42,-21,-82,-44,40,8,30,81,-84,-15,44,67,-111,83,-103,44,-127,-21,-67,32,103,28,-97,82,-49,37,85,53,76,23,-39,-21,14,10,-37,-41,79,-70,94,48,-82,-114,-66,-17,12,-81,-68,-117,103, -112,71,-74,8,65,-31,-42,-93,47,74,-19,83,-21,-70,12,52,-55,112,-75,-96,-107,-53,-42,91,-116,-52,112,-49,-16,68,33,94,-100,-55,58,19,33,-49,95,-23,-79,89,-2,-50,95,-54,37,108,-23,-42,4,72,101,64,5,-81,-116,-84,-17,-93, 
};
const TfArray<4, int> tensor_dimension4 = { 4, { 16,1,3,60 } };
const TfArray<16, float> quant4_scale = { 16, { 0.0015068452339619398, 0.0013974306639283895, 0.0016876201843842864, 0.0015146676450967789, 0.0015554656274616718, 0.0013677746756002307, 0.0014094747602939606, 0.0014790904242545366, 0.0014003737596794963, 0.0014922178816050291, 0.0013722352450713515, 0.0015766021097078919, 0.0014258463634178042, 0.0016098852502182126, 0.0015447108307853341, 0.0014608170604333282, } };
const TfArray<16, int> quant4_zero = { 16, { 0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0 } };
const TfLiteAffineQuantization quant4 = { (TfLiteFloatArray*)&quant4_scale, (TfLiteIntArray*)&quant4_zero, 0 };
const ALIGN(16) int32_t tensor_data5[16] = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, };
const TfArray<1, int> tensor_dimension5 = { 1, { 16 } };
const TfArray<16, float> quant5_scale = { 16, { 0.41348710656166077, 0.38346311450004578, 0.46309280395507812, 0.41563361883163452, 0.42682883143424988, 0.37532532215118408, 0.38676807284355164, 0.40587103366851807, 0.38427072763442993, 0.40947327017784119, 0.37654933333396912, 0.4326288104057312, 0.3912605345249176, 0.44176188111305237, 0.42387765645980835, 0.40085670351982117, } };
const TfArray<16, int> quant5_zero = { 16, { 0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0 } };
const TfLiteAffineQuantization quant5 = { (TfLiteFloatArray*)&quant5_scale, (TfLiteIntArray*)&quant5_zero, 0 };
const ALIGN(16) int8_t tensor_data6[4*48] = { 
  -85, 6, -94, 62, -25, 25, -73, -8, -70, 71, 92, -112, 87, -12, -29, -44, -56, 50, -65, 36, -106, -59, -34, 77, 79, -47, 1, 36, -57, 58, 89, -112, 97, -116, -20, -43, -30, -14, -42, 22, -108, 2, -92, 99, -21, -35, 94, -15, 
  -81, 81, -36, -9, 88, -56, -56, 35, -80, -102, 30, -77, -75, 48, -25, 88, -4, 88, 73, -89, -42, 99, 84, -81, 64, 16, -113, -29, 40, 103, -32, -70, -91, -69, -1, -96, -44, -92, 126, -50, -55, -84, 127, 23, 11, 43, -103, -24, 
  -95, 73, -7, -6, 59, 19, 2, 11, -94, 41, 65, 66, -71, 90, -5, 35, 4, 9, -10, -117, 80, 42, -109, 97, -87, -71, -49, -62, -107, 77, 34, -122, 83, 32, 103, 39, -22, 4, 13, 29, -26, 32, 4, -87, 91, -87, 45, 1, 
  -59, -49, 32, 105, 43, -56, -55, 52, 23, 102, -10, -18, 26, -11, 67, 84, -16, -36, -10, -46, 107, 98, -70, -91, -21, 98, 70, -76, 110, 41, 14, -10, -26, 64, -25, -15, -9, -101, 76, 15, 35, -49, 76, -10, 111, 22, -36, -86, 
};
const TfArray<2, int> tensor_dimension6 = { 2, { 4,48 } };
const TfArray<1, float> quant6_scale = { 1, { 0.0029438796918839216, } };
const TfArray<1, int> quant6_zero = { 1, { 0 } };
const TfLiteAffineQuantization quant6 = { (TfLiteFloatArray*)&quant6_scale, (TfLiteIntArray*)&quant6_zero, 0 };
const ALIGN(16) int32_t tensor_data7[4] = { 0, 0, 0, 0, };
const TfArray<1, int> tensor_dimension7 = { 1, { 4 } };
const TfArray<1, float> quant7_scale = { 1, { 0.64618843793869019, } };
const TfArray<1, int> quant7_zero = { 1, { 0 } };
const TfLiteAffineQuantization quant7 = { (TfLiteFloatArray*)&quant7_scale, (TfLiteIntArray*)&quant7_zero, 0 };
const TfArray<4, int> tensor_dimension8 = { 4, { 1,1,5,60 } };
const TfArray<1, float> quant8_scale = { 1, { 274.40582275390625, } };
const TfArray<1, int> quant8_zero = { 1, { -3 } };
const TfLiteAffineQuantization quant8 = { (TfLiteFloatArray*)&quant8_scale, (TfLiteIntArray*)&quant8_zero, 0 };
const TfArray<4, int> tensor_dimension9 = { 4, { 1,1,5,16 } };
const TfArray<1, float> quant9_scale = { 1, { 219.5023193359375, } };
const TfArray<1, int> quant9_zero = { 1, { -128 } };
const TfLiteAffineQuantization quant9 = { (TfLiteFloatArray*)&quant9_scale, (TfLiteIntArray*)&quant9_zero, 0 };
const TfArray<4, int> tensor_dimension10 = { 4, { 1,5,1,16 } };
const TfArray<1, float> quant10_scale = { 1, { 219.5023193359375, } };
const TfArray<1, int> quant10_zero = { 1, { -128 } };
const TfLiteAffineQuantization quant10 = { (TfLiteFloatArray*)&quant10_scale, (TfLiteIntArray*)&quant10_zero, 0 };
const TfArray<4, int> tensor_dimension11 = { 4, { 1,3,1,16 } };
const TfArray<1, float> quant11_scale = { 1, { 219.5023193359375, } };
const TfArray<1, int> quant11_zero = { 1, { -128 } };
const TfLiteAffineQuantization quant11 = { (TfLiteFloatArray*)&quant11_scale, (TfLiteIntArray*)&quant11_zero, 0 };
const TfArray<2, int> tensor_dimension12 = { 2, { 1,48 } };
const TfArray<1, float> quant12_scale = { 1, { 219.5023193359375, } };
const TfArray<1, int> quant12_zero = { 1, { -128 } };
const TfLiteAffineQuantization quant12 = { (TfLiteFloatArray*)&quant12_scale, (TfLiteIntArray*)&quant12_zero, 0 };
const TfArray<2, int> tensor_dimension13 = { 2, { 1,4 } };
const TfArray<1, float> quant13_scale = { 1, { 437.27334594726562, } };
const TfArray<1, int> quant13_zero = { 1, { -25 } };
const TfLiteAffineQuantization quant13 = { (TfLiteFloatArray*)&quant13_scale, (TfLiteIntArray*)&quant13_zero, 0 };
const TfArray<2, int> tensor_dimension14 = { 2, { 1,4 } };
const TfArray<1, float> quant14_scale = { 1, { 0.00390625, } };
const TfArray<1, int> quant14_zero = { 1, { -128 } };
const TfLiteAffineQuantization quant14 = { (TfLiteFloatArray*)&quant14_scale, (TfLiteIntArray*)&quant14_zero, 0 };
const TfLiteReshapeParams opdata0 = { { 0, 0, 0, 0, 0, 0, 0, 0, }, 0 };
const TfArray<2, int> inputs0 = { 2, { 0,1 } };
const TfArray<1, int> outputs0 = { 1, { 8 } };
const TfLiteConvParams opdata1 = { kTfLitePaddingSame, 1,1, kTfLiteActRelu, 1,1 };
const TfArray<3, int> inputs1 = { 3, { 8,4,5 } };
const TfArray<1, int> outputs1 = { 1, { 9 } };
const TfLiteReshapeParams opdata2 = { { 0, 0, 0, 0, 0, 0, 0, 0, }, 0 };
const TfArray<2, int> inputs2 = { 2, { 9,2 } };
const TfArray<1, int> outputs2 = { 1, { 10 } };
const TfLitePoolParams opdata3 = { kTfLitePaddingSame, 1,2, 1,2, kTfLiteActNone, { { 0,0, 0, 0 } } };
const TfArray<1, int> inputs3 = { 1, { 10 } };
const TfArray<1, int> outputs3 = { 1, { 11 } };
const TfLiteReshapeParams opdata4 = { { 0, 0, 0, 0, 0, 0, 0, 0, }, 0 };
const TfArray<2, int> inputs4 = { 2, { 11,3 } };
const TfArray<1, int> outputs4 = { 1, { 12 } };
const TfLiteFullyConnectedParams opdata5 = { kTfLiteActNone, kTfLiteFullyConnectedWeightsFormatDefault, false, false };
const TfArray<3, int> inputs5 = { 3, { 12,6,7 } };
const TfArray<1, int> outputs5 = { 1, { 13 } };
const TfLiteSoftmaxParams opdata6 = { 1 };
const TfArray<1, int> inputs6 = { 1, { 13 } };
const TfArray<1, int> outputs6 = { 1, { 14 } };
const TensorInfo_t tensorData[] = {
  { kTfLiteArenaRw, kTfLiteInt8, tensor_arena + 0, (TfLiteIntArray*)&tensor_dimension0, 300, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant0))}, },
  { kTfLiteMmapRo, kTfLiteInt32, (void*)tensor_data1, (TfLiteIntArray*)&tensor_dimension1, 16, {kTfLiteNoQuantization, nullptr}, },
  { kTfLiteMmapRo, kTfLiteInt32, (void*)tensor_data2, (TfLiteIntArray*)&tensor_dimension2, 16, {kTfLiteNoQuantization, nullptr}, },
  { kTfLiteMmapRo, kTfLiteInt32, (void*)tensor_data3, (TfLiteIntArray*)&tensor_dimension3, 8, {kTfLiteNoQuantization, nullptr}, },
  { kTfLiteMmapRo, kTfLiteInt8, (void*)tensor_data4, (TfLiteIntArray*)&tensor_dimension4, 2880, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant4))}, },
  { kTfLiteMmapRo, kTfLiteInt32, (void*)tensor_data5, (TfLiteIntArray*)&tensor_dimension5, 64, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant5))}, },
  { kTfLiteMmapRo, kTfLiteInt8, (void*)tensor_data6, (TfLiteIntArray*)&tensor_dimension6, 192, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant6))}, },
  { kTfLiteMmapRo, kTfLiteInt32, (void*)tensor_data7, (TfLiteIntArray*)&tensor_dimension7, 16, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant7))}, },
  { kTfLiteArenaRw, kTfLiteInt8, tensor_arena + 720, (TfLiteIntArray*)&tensor_dimension8, 300, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant8))}, },
  { kTfLiteArenaRw, kTfLiteInt8, tensor_arena + 1024, (TfLiteIntArray*)&tensor_dimension9, 80, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant9))}, },
  { kTfLiteArenaRw, kTfLiteInt8, tensor_arena + 0, (TfLiteIntArray*)&tensor_dimension10, 80, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant10))}, },
  { kTfLiteArenaRw, kTfLiteInt8, tensor_arena + 80, (TfLiteIntArray*)&tensor_dimension11, 48, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant11))}, },
  { kTfLiteArenaRw, kTfLiteInt8, tensor_arena + 0, (TfLiteIntArray*)&tensor_dimension12, 48, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant12))}, },
  { kTfLiteArenaRw, kTfLiteInt8, tensor_arena + 48, (TfLiteIntArray*)&tensor_dimension13, 4, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant13))}, },
  { kTfLiteArenaRw, kTfLiteInt8, tensor_arena + 0, (TfLiteIntArray*)&tensor_dimension14, 4, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant14))}, },
};const NodeInfo_t nodeData[] = {
  { (TfLiteIntArray*)&inputs0, (TfLiteIntArray*)&outputs0, const_cast<void*>(static_cast<const void*>(&opdata0)), OP_RESHAPE, },
  { (TfLiteIntArray*)&inputs1, (TfLiteIntArray*)&outputs1, const_cast<void*>(static_cast<const void*>(&opdata1)), OP_CONV_2D, },
  { (TfLiteIntArray*)&inputs2, (TfLiteIntArray*)&outputs2, const_cast<void*>(static_cast<const void*>(&opdata2)), OP_RESHAPE, },
  { (TfLiteIntArray*)&inputs3, (TfLiteIntArray*)&outputs3, const_cast<void*>(static_cast<const void*>(&opdata3)), OP_MAX_POOL_2D, },
  { (TfLiteIntArray*)&inputs4, (TfLiteIntArray*)&outputs4, const_cast<void*>(static_cast<const void*>(&opdata4)), OP_RESHAPE, },
  { (TfLiteIntArray*)&inputs5, (TfLiteIntArray*)&outputs5, const_cast<void*>(static_cast<const void*>(&opdata5)), OP_FULLY_CONNECTED, },
  { (TfLiteIntArray*)&inputs6, (TfLiteIntArray*)&outputs6, const_cast<void*>(static_cast<const void*>(&opdata6)), OP_SOFTMAX, },
};
static std::vector<void*> overflow_buffers;
static void * AllocatePersistentBuffer(struct TfLiteContext* ctx,
                                       size_t bytes) {
  void *ptr;
  if (current_location - bytes < tensor_boundary) {
    // OK, this will look super weird, but.... we have CMSIS-NN buffers which
    // we cannot calculate beforehand easily.
    ptr = ei_calloc(bytes, 1);
    if (ptr == NULL) {
      printf("ERR: Failed to allocate persistent buffer of size %d\n", (int)bytes);
      return NULL;
    }
    overflow_buffers.push_back(ptr);
    return ptr;
  }

  current_location -= bytes;

  ptr = current_location;
  memset(ptr, 0, bytes);

  return ptr;
}
typedef struct {
  size_t bytes;
  void *ptr;
} scratch_buffer_t;
static std::vector<scratch_buffer_t> scratch_buffers;

static TfLiteStatus RequestScratchBufferInArena(struct TfLiteContext* ctx, size_t bytes,
                                                int* buffer_idx) {
  scratch_buffer_t b;
  b.bytes = bytes;

  b.ptr = AllocatePersistentBuffer(ctx, b.bytes);
  if (!b.ptr) {
    return kTfLiteError;
  }

  scratch_buffers.push_back(b);

  *buffer_idx = scratch_buffers.size() - 1;

  return kTfLiteOk;
}

static void* GetScratchBuffer(struct TfLiteContext* ctx, int buffer_idx) {
  if (buffer_idx > static_cast<int>(scratch_buffers.size()) - 1) {
    return NULL;
  }
  return scratch_buffers[buffer_idx].ptr;
}

static TfLiteTensor* GetTensor(const struct TfLiteContext* context,
                               int tensor_idx) {
  return &tflTensors[tensor_idx];
}

static TfLiteEvalTensor* GetEvalTensor(const struct TfLiteContext* context,
                                       int tensor_idx) {
  return &tflEvalTensors[tensor_idx];
}

} // namespace

TfLiteStatus trained_model_init( void*(*alloc_fnc)(size_t,size_t) ) {
#ifdef EI_CLASSIFIER_ALLOCATION_HEAP
  tensor_arena = (uint8_t*) alloc_fnc(16, kTensorArenaSize);
  if (!tensor_arena) {
    printf("ERR: failed to allocate tensor arena\n");
    return kTfLiteError;
  }
#else
  memset(tensor_arena, 0, kTensorArenaSize);
#endif
  tensor_boundary = tensor_arena;
  current_location = tensor_arena + kTensorArenaSize;
  ctx.AllocatePersistentBuffer = &AllocatePersistentBuffer;
  ctx.RequestScratchBufferInArena = &RequestScratchBufferInArena;
  ctx.GetScratchBuffer = &GetScratchBuffer;
  ctx.GetTensor = &GetTensor;
  ctx.GetEvalTensor = &GetEvalTensor;
  ctx.tensors = tflTensors;
  ctx.tensors_size = 15;
  for(size_t i = 0; i < 15; ++i) {
    tflTensors[i].type = tensorData[i].type;
    tflEvalTensors[i].type = tensorData[i].type;
    tflTensors[i].is_variable = 0;

#if defined(EI_CLASSIFIER_ALLOCATION_HEAP)
    tflTensors[i].allocation_type = tensorData[i].allocation_type;
#else
    tflTensors[i].allocation_type = (tensor_arena <= tensorData[i].data && tensorData[i].data < tensor_arena + kTensorArenaSize) ? kTfLiteArenaRw : kTfLiteMmapRo;
#endif
    tflTensors[i].bytes = tensorData[i].bytes;
    tflTensors[i].dims = tensorData[i].dims;
    tflEvalTensors[i].dims = tensorData[i].dims;

#if defined(EI_CLASSIFIER_ALLOCATION_HEAP)
    if(tflTensors[i].allocation_type == kTfLiteArenaRw){
      uint8_t* start = (uint8_t*) ((uintptr_t)tensorData[i].data + (uintptr_t) tensor_arena);

     tflTensors[i].data.data =  start;
     tflEvalTensors[i].data.data =  start;
    }
    else{
       tflTensors[i].data.data = tensorData[i].data;
       tflEvalTensors[i].data.data = tensorData[i].data;
    }
#else
    tflTensors[i].data.data = tensorData[i].data;
    tflEvalTensors[i].data.data = tensorData[i].data;
#endif // EI_CLASSIFIER_ALLOCATION_HEAP
    tflTensors[i].quantization = tensorData[i].quantization;
    if (tflTensors[i].quantization.type == kTfLiteAffineQuantization) {
      TfLiteAffineQuantization const* quant = ((TfLiteAffineQuantization const*)(tensorData[i].quantization.params));
      tflTensors[i].params.scale = quant->scale->data[0];
      tflTensors[i].params.zero_point = quant->zero_point->data[0];
    }
    if (tflTensors[i].allocation_type == kTfLiteArenaRw) {
      auto data_end_ptr = (uint8_t*)tflTensors[i].data.data + tensorData[i].bytes;
      if (data_end_ptr > tensor_boundary) {
        tensor_boundary = data_end_ptr;
      }
    }
  }
  if (tensor_boundary > current_location /* end of arena size */) {
    printf("ERR: tensor arena is too small, does not fit model - even without scratch buffers\n");
    return kTfLiteError;
  }
  registrations[OP_RESHAPE] = Register_RESHAPE();
  registrations[OP_CONV_2D] = Register_CONV_2D();
  registrations[OP_MAX_POOL_2D] = Register_MAX_POOL_2D();
  registrations[OP_FULLY_CONNECTED] = Register_FULLY_CONNECTED();
  registrations[OP_SOFTMAX] = Register_SOFTMAX();

  for(size_t i = 0; i < 7; ++i) {
    tflNodes[i].inputs = nodeData[i].inputs;
    tflNodes[i].outputs = nodeData[i].outputs;
    tflNodes[i].builtin_data = nodeData[i].builtin_data;
tflNodes[i].custom_initial_data = nullptr;
      tflNodes[i].custom_initial_data_size = 0;
if (registrations[nodeData[i].used_op_index].init) {
      tflNodes[i].user_data = registrations[nodeData[i].used_op_index].init(&ctx, (const char*)tflNodes[i].builtin_data, 0);
    }
  }
  for(size_t i = 0; i < 7; ++i) {
    if (registrations[nodeData[i].used_op_index].prepare) {
      TfLiteStatus status = registrations[nodeData[i].used_op_index].prepare(&ctx, &tflNodes[i]);
      if (status != kTfLiteOk) {
        return status;
      }
    }
  }
  return kTfLiteOk;
}

static const int inTensorIndices[] = {
  0, 
};
TfLiteTensor* trained_model_input(int index) {
  return &ctx.tensors[inTensorIndices[index]];
}

static const int outTensorIndices[] = {
  14, 
};
TfLiteTensor* trained_model_output(int index) {
  return &ctx.tensors[outTensorIndices[index]];
}

TfLiteStatus trained_model_invoke() {
  for(size_t i = 0; i < 7; ++i) {
    TfLiteStatus status = registrations[nodeData[i].used_op_index].invoke(&ctx, &tflNodes[i]);

#if EI_CLASSIFIER_PRINT_STATE
    ei_printf("layer %lu\n", i);
    ei_printf("    inputs:\n");
    for (size_t ix = 0; ix < tflNodes[i].inputs->size; ix++) {
      auto d = tensorData[tflNodes[i].inputs->data[ix]];

      size_t data_ptr = (size_t)d.data;

      if (d.allocation_type == kTfLiteArenaRw) {
        data_ptr = (size_t)tensor_arena + data_ptr;
      }

      if (d.type == TfLiteType::kTfLiteInt8) {
        int8_t* data = (int8_t*)data_ptr;
        ei_printf("        %lu (%zu bytes, ptr=%p, alloc_type=%d, type=%d): ", ix, d.bytes, data, (int)d.allocation_type, (int)d.type);
        for (size_t jx = 0; jx < d.bytes; jx++) {
          ei_printf("%d ", data[jx]);
        }
      }
      else {
        float* data = (float*)data_ptr;
        ei_printf("        %lu (%zu bytes, ptr=%p, alloc_type=%d, type=%d): ", ix, d.bytes, data, (int)d.allocation_type, (int)d.type);
        for (size_t jx = 0; jx < d.bytes / 4; jx++) {
          ei_printf("%f ", data[jx]);
        }
      }
      ei_printf("\n");
    }
    ei_printf("\n");

    ei_printf("    outputs:\n");
    for (size_t ix = 0; ix < tflNodes[i].outputs->size; ix++) {
      auto d = tensorData[tflNodes[i].outputs->data[ix]];

      size_t data_ptr = (size_t)d.data;

      if (d.allocation_type == kTfLiteArenaRw) {
        data_ptr = (size_t)tensor_arena + data_ptr;
      }

      if (d.type == TfLiteType::kTfLiteInt8) {
        int8_t* data = (int8_t*)data_ptr;
        ei_printf("        %lu (%zu bytes, ptr=%p, alloc_type=%d, type=%d): ", ix, d.bytes, data, (int)d.allocation_type, (int)d.type);
        for (size_t jx = 0; jx < d.bytes; jx++) {
          ei_printf("%d ", data[jx]);
        }
      }
      else {
        float* data = (float*)data_ptr;
        ei_printf("        %lu (%zu bytes, ptr=%p, alloc_type=%d, type=%d): ", ix, d.bytes, data, (int)d.allocation_type, (int)d.type);
        for (size_t jx = 0; jx < d.bytes / 4; jx++) {
          ei_printf("%f ", data[jx]);
        }
      }
      ei_printf("\n");
    }
    ei_printf("\n");
#endif // EI_CLASSIFIER_PRINT_STATE

    if (status != kTfLiteOk) {
      return status;
    }
  }
  return kTfLiteOk;
}

TfLiteStatus trained_model_reset( void (*free_fnc)(void* ptr) ) {
#ifdef EI_CLASSIFIER_ALLOCATION_HEAP
  free_fnc(tensor_arena);
#endif
  scratch_buffers.clear();
  for (size_t ix = 0; ix < overflow_buffers.size(); ix++) {
    free(overflow_buffers[ix]);
  }
  overflow_buffers.clear();
  return kTfLiteOk;
}
